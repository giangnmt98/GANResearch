"""
Module containing the implementation of WGANGPLoss
for training Wasserstein GAN with Gradient Penalty.
"""

import torch

from ganresearch.losses.losses import Losses


class WGANGPLoss(Losses):
    """
    Class implementing the Wasserstein GAN with Gradient Penalty loss.

    Attributes:
        config (dict): Configuration parameters for the loss function.
    """

    def __init__(self, config):
        """
        Initialize the WGANGPLoss with the provided configuration.

        Args:
            config (dict): Configuration parameters.
        """
        super().__init__(config)

    def calculate_loss(
        self,
        real_output: torch.Tensor,
        fake_output: torch.Tensor,
        is_discriminator: bool = True,
        epoch: int = None,
        critic=None,
        real_data: torch.Tensor = None,
        fake_data: torch.Tensor = None,
        device=None,
    ) -> torch.Tensor:
        """
        Calculate the loss for the Wasserstein GAN with Gradient Penalty.

        Args:
            real_output (torch.Tensor): Output from the discriminator for real data.
            fake_output (torch.Tensor): Output from the discriminator for fake data.
            is_discriminator (bool, optional): Indicate if the loss is for the discriminator.
            epoch (int, optional): Current epoch number.
            critic (optional): Critic model.
            real_data (torch.Tensor, optional): Real data samples.
            fake_data (torch.Tensor, optional): Fake data samples generated by the generator.
            device (optional): Device to perform computation on.

        Returns:
            torch.Tensor: Calculated loss.
        """
        lambda_gp = self.config["training"]["lambda_gp"]

        # Calculate the gradient penalty
        gp = self.gradient_penalty(critic, real_data, fake_data, device)

        if self.ema is not None:
            # Update EMA for real and fake outputs
            self.ema.update(torch.mean(fake_output).item(), "D_fake", epoch)
            self.ema.update(torch.mean(real_output).item(), "D_real", epoch)

        # Calculate LeCam regularization term if conditions are met
        if self.use_lecam and self.lecam_ratio > 0 and epoch > self.ema.start_epoch:
            loss_lecam = self.lecam_reg(real_output, fake_output) * self.lecam_ratio
        else:
            loss_lecam = torch.tensor(0.0)

        # Return the total loss combining WGAN-GP loss and LeCam regularization
        return (fake_output - real_output + lambda_gp * gp) + loss_lecam

    def gradient_penalty(
        self, critic, real_data: torch.Tensor, fake_data: torch.Tensor, device
    ) -> torch.Tensor:
        """
        Calculate the gradient penalty for the Wasserstein GAN.

        Args:
            critic: Critic model.
            real_data (torch.Tensor): Real data samples.
            fake_data (torch.Tensor): Fake data samples generated by the generator.
            device: Device to perform computation on.

        Returns:
            torch.Tensor: Calculated gradient penalty.
        """
        batch_size = real_data.size(0)

        # Generate random epsilon values for interpolation
        epsilon = torch.rand(batch_size, 1, 1, 1, device=device)

        # Create interpolated samples between real and fake data
        interpolated = epsilon * real_data + (1 - epsilon) * fake_data
        interpolated.requires_grad_(True)

        # Pass interpolated samples through the critic model
        score_interpolated = critic(interpolated)

        # Create gradient outputs for autograd
        grad_outputs = torch.ones_like(score_interpolated, device=device)

        # Compute gradients of critic scores with respect to interpolated samples
        gradients = torch.autograd.grad(
            outputs=score_interpolated,
            inputs=interpolated,
            grad_outputs=grad_outputs,
            create_graph=True,
            retain_graph=True,
            only_inputs=True,
        )[0]

        # Reshape gradients to compute norms
        gradients = gradients.view(batch_size, -1)

        # Compute norm of gradients
        gradient_norm = gradients.norm(2, dim=1)

        # Calculate the gradient penalty term
        penalty = ((gradient_norm - 1) ** 2).mean()

        return penalty
